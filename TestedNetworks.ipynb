{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCNN\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding(input_dim, embedding_size)(inp)\n",
    "    \n",
    "    dense0 = Dense(128, activation='relu')(emb)\n",
    "    \n",
    "    reduce = tf.reduce_mean(dense0, axis=1)\n",
    "    \n",
    "    dense = Dense(128, activation='relu')(reduce)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(total_attacks, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding(input_dim, embedding_size)(inp)\n",
    "    \n",
    "    rnn = SimpleRNN(128, return_sequences=True)(emb)\n",
    "    \n",
    "    # squish into (None, 64) from (None, None, 64)\n",
    "    reduce = tf.reduce_mean(rnn, axis=1)\n",
    "    \n",
    "    dense = Dense(128, activation='relu')(reduce)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(total_attacks, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding(input_dim, embedding_size)(inp)\n",
    "    \n",
    "    cnn = Conv1D( filters=128, kernel_size=3, strides=1, use_bias=True, activation='relu', padding='valid' )(emb)\n",
    "    \n",
    "    # squish into (None, 64) from (None, None, 64)\n",
    "    reduce = tf.reduce_mean(cnn, axis=1)\n",
    "    \n",
    "    dense = Dense(128, activation='relu')(reduce)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(total_attacks, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leap-LSTM custom code\n",
    "def sample_gumbel(shape, eps=1e-20): \n",
    "    \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "    U = tf.random.uniform(shape,minval=0,maxval=1)\n",
    "    return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
    "    \n",
    "    \n",
    "def gumbel_softmax_sample(logits, temperature=1e-5): \n",
    "    \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "    y = logits + sample_gumbel(tf.shape(logits))\n",
    "    return tf.nn.softmax(y / temperature)\n",
    "\n",
    "\n",
    "'''\n",
    "Modern Tensorflow Implementation of leap-LSTM: \n",
    "'''\n",
    "\n",
    "\n",
    "class leapLSTM(keras.layers.Layer):\n",
    "    '''\n",
    "    num_cells: number of nodes in the layer\n",
    "    name: name for the layer\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_cells=100, name='lstm', small_cell_size=10, **kwargs):\n",
    "        super(leapLSTM, self).__init__(name=name, **kwargs)\n",
    "        self.num_cells = num_cells\n",
    "        self.rnn_cell = LSTMCell(self.num_cells)\n",
    "        self.dense0 = Dense(100, activation=\"relu\", use_bias=True)\n",
    "        self.dense1 = Dense(2, use_bias=True)\n",
    "\n",
    "        self.conv1=Conv1D(60, 3, padding = 'same')\n",
    "        self.conv2=Conv1D(60, 4, padding = 'same')\n",
    "        self.conv3=Conv1D(60, 5, padding = 'same')\n",
    "        self.rnn_rev=LSTM(10, return_sequences=True)  # p\n",
    "\n",
    "\n",
    "    # Build the basic cells. Done automatically for dense layer\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape=input_shape[0]\n",
    "        if not self.rnn_cell.built:\n",
    "            with keras.backend.name_scope(self.rnn_cell.name):\n",
    "                self.rnn_cell.build(input_shape)\n",
    "                self.rnn_cell.built=True\n",
    "\n",
    "        self.built=True\n",
    "\n",
    "    # Used when this layer is part of a network\n",
    "    # o_inputs is of shape [batch, window size, embedding_dim]\n",
    "    def call(self, o_inputs, **kwargs):\n",
    "        # o_inputs is of shape [batch, window size, embedding_dim]\n",
    "        batch_size=tf.shape(o_inputs)[0]\n",
    "        win_size=tf.shape(o_inputs)[1]\n",
    "        enb_size=tf.shape(o_inputs)[2]\n",
    "\n",
    "        results=tf.TensorArray(dtype = tf.float32, size = win_size)\n",
    "\n",
    "\n",
    "        conved=tf.concat([\n",
    "            self.conv1(o_inputs),\n",
    "            self.conv2(o_inputs),\n",
    "            self.conv3(o_inputs)],\n",
    "            axis = -1)\n",
    "        # shape = [batch, time, 60*3]\n",
    "\n",
    "\n",
    "        rev_lstm=self.rnn_rev(\n",
    "            tf.reverse(\n",
    "                o_inputs, axis=[1]\n",
    "            )\n",
    "        )\n",
    "        # shape = [batch, time, 10]\n",
    "\n",
    "        f_all=tf.concat([conved, rev_lstm], axis = -1)\n",
    "        # shape = [batch, time, 190]\n",
    "\n",
    "        h_end=tf.zeros(shape = [batch_size, 190])\n",
    "        # shape = [batch, 190]\n",
    "        \n",
    "        \n",
    "        f_all=tf.concat([\n",
    "            f_all, \n",
    "            tf.expand_dims(h_end, axis=1)\n",
    "        ], axis=1)\n",
    "        # shape = [batch, time+1, 190]\n",
    "\n",
    "        '''\n",
    "        This function is applied to each timestamp of the sequence for the node\n",
    "        Inputs/Outputs:\n",
    "            t: current timestamp\n",
    "            state:  array containing: [ht_1, ct_1]: hidden and candidates from previous timestamp\n",
    "            res: stacking array containing node output values\n",
    "        '''\n",
    "        def _step(t, ht_1, res):\n",
    "\n",
    "            x_t=o_inputs[:, t, :]\n",
    "\n",
    "            ff=f_all[:, t+1, :]\n",
    "   \n",
    "            \n",
    "            pi_t = self.dense1(\n",
    "                self.dense0(\n",
    "                    tf.concat([ff, x_t], axis=-1)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            d_t = gumbel_softmax_sample(pi_t) # tf tensor\n",
    "            # [None, 2] 2: (keep, skip)\n",
    "            \n",
    "            \n",
    "            # generate output for current timestamp t (Eq 3)\n",
    "            (out, ht_candidate) = self.rnn_cell(x_t, ht_1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # make d_t rank 3 tensor so after slicing it will become rank-2\n",
    "            d_t = tf.expand_dims(d_t, [1])\n",
    "            # [None, 1, 2]\n",
    "            \n",
    "            ht = [\n",
    "                d_t[:,:,0] * ht_candidate[0] + d_t[:,:,1] * ht_1[0], # combing keep & skip for lstm state h (element 0)\n",
    "                d_t[:,:,0] * ht_candidate[1] + d_t[:,:,1] * ht_1[1], # combing keep & skip for lstm state c (element 1)\n",
    "            ]\n",
    "            \n",
    "            # ht = tf.equal(d_t, 0) * ht_candidate + (1 - tf.equal(d_t, 0)) * ht_1\n",
    "            \n",
    "            # write node output to index t of array res (returned the updated res array)\n",
    "            res_updated = res.write(t, out)\n",
    "            \n",
    "            return t+1, ht, res_updated\n",
    "        \n",
    "        # inital state\n",
    "        state0 = _generate_zero_filled_state_for_cell(self.rnn_cell, o_inputs, None, None)\n",
    "        \n",
    "        *_, final_res = tf.while_loop(\n",
    "            lambda t, *_: t < win_size, \n",
    "            _step,\n",
    "            (0, state0, results)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        final_res = final_res.stack()\n",
    "        # [time, batch, cell_dim]\n",
    "        final_res = tf.transpose(final_res, [1, 0, 2])\n",
    "        # [batch, time, cell_dim]\n",
    "        return final_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leap-LSTM\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding(input_dim, embedding_size)(inp)\n",
    "    \n",
    "    rec1 = leapLSTM(128, name=\"leap\")(emb)\n",
    "    \n",
    "    # squish into (None, 64) from (None, None, 64)\n",
    "    reduce = tf.reduce_mean(rec1, axis=1)\n",
    "    \n",
    "    dense = Dense(128, activation='relu')(reduce)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(total_attacks, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BI-LSTM\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding(input_dim, embedding_size)(inp)\n",
    "    \n",
    "    lstm1 = Bidirectional(LSTM(32, return_sequences=True))(emb) #[None,40,8]\n",
    "    lstm2 = Bidirectional(LSTM(128))(lstm1) #[None,32]\n",
    "    \n",
    "    \n",
    "    dense = Dense(128, activation='relu')(lstm2)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(total_attacks, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding(input_dim, embedding_size)(inp)\n",
    "    \n",
    "    rec1 = leapLSTM(128, name=\"leap\")(emb)\n",
    "    \n",
    "    # squish into (None, 64) from (None, None, 64)\n",
    "    reduce = tf.reduce_mean(rec1, axis=1)\n",
    "    \n",
    "    dense = Dense(128, activation='relu')(reduce)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(total_attacks, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCNN\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding( input_dim, embedding_size)(inp)\n",
    "    filt = Conv1D( filters=128, kernel_size=3, strides=1, use_bias=True, activation='relu', padding='valid' )(emb)\n",
    "    attn = Conv1D( filters=128, kernel_size=3, strides=1, use_bias=True, activation='sigmoid', padding='valid')(emb)\n",
    "    gated = Multiply()([filt,attn])\n",
    "    feat = GlobalMaxPooling1D()( gated )\n",
    "    dense = Dense(128, activation='relu')(feat)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(11, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
