{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jsonpickle elasticsearch elasticsearch_dsl opencv-python\n",
    "from odf import *\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JSON from 'data' folder into python array\n",
    "# final version uses mega-dump with 501 files\n",
    "folder = 'data'\n",
    "data = [\n",
    "    jsonpickle.decode(\n",
    "    Path(os.path.join(folder, f)).read_text()\n",
    "    ) for f in tqdm(os.listdir(folder))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-advertiser",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "converts a word sent over the bus into its component parts\n",
    "returns: an array containing an integer representing each piece of the message, the class (attack type) label\n",
    "'''\n",
    "def word2seq(t:int, w: Word):\n",
    "    def _inner():\n",
    "        if isinstance(w, Data):\n",
    "            return list(w.data)\n",
    "        if isinstance(w, Command):\n",
    "            return [\n",
    "                w.address, \n",
    "                w.tr, \n",
    "                w.sub_address, \n",
    "                w.dword_count\n",
    "            ]\n",
    "        if isinstance(w, Status):\n",
    "            return [\n",
    "                w.address, \n",
    "                w.message_error_bit, \n",
    "                w.instrumentation_bit, \n",
    "                w.service_request_bit,\n",
    "                w.reserved_bits,\n",
    "                w.brdcst_received_bit,\n",
    "                w.busy_bit,\n",
    "                w.subsystem_flag_bit,\n",
    "                w.dynamic_bus_control_accpt_bit,\n",
    "                w.terminal_flag_bit,\n",
    "                w.parity_bit,\n",
    "            ]    \n",
    "    return [int(i) for i in _inner()], w.fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_attacks defined in odf package\n",
    "total_attacks = 11\n",
    "\n",
    "# convert the attack type listed into an integer (for classification)\n",
    "def attk2index(attk):\n",
    "    # string to attack index\n",
    "    for i, a in enumerate(all_attacks):\n",
    "        if a.__name__ == attk:\n",
    "            return i+1\n",
    "    return 0\n",
    "\n",
    "'''\n",
    "Converts the raw JSON file into data format which can be interpreted by the network\n",
    "Inputs\n",
    "    session: array of arrays containing [[timestamp, word]...] for each message\n",
    "    size: maximum allowed sequence length in number of words\n",
    "Output:\n",
    "    array of tuples containing: (sequence, attack label (T/F), attack type)\n",
    "'''\n",
    "def file2sample(session, size=5):\n",
    "    # load the words sent over the bus\n",
    "    words = [word2seq(*d) for d in session['data']]\n",
    "\n",
    "    # empty output array\n",
    "    windows = []\n",
    "    # loop through each word sent on the bus\n",
    "    for i in range(len(words)):\n",
    "        # get a sequence of command words from the overall list (depending on size)\n",
    "        win = words[max(0, i-size+1):i+1]\n",
    "        # extract the sequence of information being sent in the word\n",
    "        x = [i for w in win for i in w[0]]\n",
    "        # extract the class label for each word\n",
    "        y = [w[1] for w in win]\n",
    "        if len(win) == size:\n",
    "            # append (sequence, label, type) to output array\n",
    "            # check if any of the commands that were part of the sequence are malicious\n",
    "            # if so, label the whole sequence as malicious\n",
    "            # also determine specifically which type of attack is occuring\n",
    "            windows.append((x, 1 if any(y) else 0, attk2index(session['attack_types'][0] if any(y) else 'NA')))\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# window size\n",
    "max_win = 10\n",
    "\n",
    "ds = [s for d in tqdm(data) for s in file2sample(d, size=max_win)]\n",
    "# the sequences need to be padded so the length matches\n",
    "# problem: each sequence has a different length depending on type of word (data, status, command)\n",
    "x = pad_sequences([d[0] for d in ds], padding='post',)\n",
    "# convert class into numpy array\n",
    "y = np.array([d[1] for d in ds])\n",
    "# convert attack type into numpy array\n",
    "z = np.array([d[2] for d in ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important note: each one has a different number of data points associated depending on the type of word\n",
    "# so the padding is weird\n",
    "\n",
    "for i in range(3):\n",
    "    # (sequence, anomaly label, attack class)\n",
    "    print(x[i], y[i], z[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import (Conv1D, Flatten, Dense, \n",
    "                                     Dropout, Input, Multiply, \n",
    "                                     Embedding, GlobalMaxPooling1D,\n",
    "                                     LSTM, RepeatVector,GRU, SimpleRNN, Bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, GRUCell, GRU, RNN, Flatten, LSTMCell\n",
    "from tensorflow.python.keras.layers.recurrent import _generate_zero_filled_state_for_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCNN\n",
    "def build():\n",
    "    input_dim = 256 # maximum integer \n",
    "    padding_char = 256\n",
    "    embedding_size = 8 \n",
    "\n",
    "    inp = Input( shape=(None,), dtype='int64')\n",
    "    emb = Embedding( input_dim, embedding_size)(inp)\n",
    "    filt = Conv1D( filters=128, kernel_size=3, strides=1, use_bias=True, activation='relu', padding='valid' )(emb)\n",
    "    attn = Conv1D( filters=128, kernel_size=3, strides=1, use_bias=True, activation='sigmoid', padding='valid')(emb)\n",
    "    gated = Multiply()([filt,attn])\n",
    "    feat = GlobalMaxPooling1D()( gated )\n",
    "    dense = Dense(128, activation='relu')(feat)\n",
    "    out_anomaly = Dense(1, activation='sigmoid', name='anomaly')(dense)\n",
    "    out_misuse = Dense(11, activation='softmax', name='misuse')(dense)\n",
    " \n",
    "    model = tf.keras.Model(inp, (out_anomaly, out_misuse))\n",
    "    model.compile(\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], \n",
    "        optimizer='adam',\n",
    "        metrics=[['binary_accuracy', 'AUC', 'Precision', 'Recall'], ['SparseCategoricalAccuracy']]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% training data, set verbose=1 to show training progress\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(x, (y, z), validation_split=0.90, epochs=15, batch_size=1024, verbose=1) \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final performance \n",
    "\n",
    "precision = history.history['val_anomaly_precision'][-1]\n",
    "recall = history.history['val_anomaly_recall'][-1]\n",
    "\n",
    "print(\"Precision: \" + str(history.history['val_anomaly_precision'][-1]))\n",
    "print(\"Recall: \" + str(history.history['val_anomaly_recall'][-1]))\n",
    "print(\"F1: \" + str(2 * ((precision*recall)/(precision+recall))) )\n",
    "print(\"AUC: \" + str(history.history['val_anomaly_auc'][-1]))\n",
    "print(\"SCA: \" +  str(history.history['val_misuse_sparse_categorical_accuracy'][-1]))\n",
    "print(\"Runtime: \" + str(end - start) + \"s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
